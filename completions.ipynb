{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt messages sent to OpenAI API:[{'role': 'user', 'content': 'Of course! Can you please provide me with the location or specific type of cuisine you are looking for so that I can make a tailored recommendation for you?'}]\n",
      "Prompt messages sent to OpenAI API:[{'role': 'user', 'content': 'I am looking for a nice Italian restaurant in the downtown area.'}]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I would recommend checking out Osteria Morini located in the downtown area. They offer a delicious selection of traditional Italian dishes and have a cozy atmosphere perfect for a nice dinner. You can also try L'Artusi or Babbo for a more upscale dining experience. Enjoy your meal!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "name = \"gpt-3.5-turbo memory-1 user\"\n",
    "model = \"gpt-3.5-turbo\"               # important options: \"gpt-4o-mini\", \"gpt-4o\", \"gpt-3.5-turbo\"\n",
    "n = 2\n",
    "memory = 1\n",
    "stable_system_message = False\n",
    "assistant_transform = True    \n",
    "assistant_transform_type = \"user\"     # options: \"user\", \"user-assistant\", \"system\"\n",
    "\n",
    "first_prompt = [\n",
    "  #{\"role\": \"system\", \"content\": \"\"},\n",
    "  {\"role\": \"user\", \"content\": \"\"}\n",
    "]\n",
    "\n",
    "def create_completions(name,n,memory,stable_system_message,assistant_transform,assistant_transform_type,first_prompt):\n",
    "\n",
    "  for iteration in range(n):\n",
    "    # Load completions from json, if continuing with a file generated in the past\n",
    "\n",
    "    try:\n",
    "      with open(f\"{name}.json\", \"r\") as json_file:\n",
    "        completions=json.load(json_file)\n",
    "\n",
    "    # If not, create a new completions database\n",
    "\n",
    "    except FileNotFoundError:\n",
    "      completions = []\n",
    "\n",
    "    # Collect messages generated so far\n",
    "\n",
    "    messages = first_prompt\n",
    "    for completion in completions:\n",
    "        message = completion[\"choices\"][0][\"message\"]\n",
    "        messages.append({\"role\": message[\"role\"], \"content\": message[\"content\"]}   \n",
    "        )\n",
    "\n",
    "    # Pick prompt messages\n",
    "\n",
    "    if memory >= len(messages):\n",
    "        prompt_messages = messages\n",
    "    else:\n",
    "        #print(f\"Memory smaller than the entire conversation. Forgetting {len(messages)-memory} messages\")\n",
    "        prompt_messages = []\n",
    "        if stable_system_message:\n",
    "          prompt_messages.append(first_prompt[0])\n",
    "          print(prompt_messages)\n",
    "          print(\"stable_system_message\")\n",
    "        prompt_messages = prompt_messages+messages[(len(messages)-memory):]\n",
    "\n",
    "    # Transform assistant role to assistant and user, user, or system roles\n",
    "\n",
    "    if assistant_transform:\n",
    "      if assistant_transform_type == \"user-assistant\":\n",
    "        i = 1\n",
    "        while i <= len(prompt_messages):\n",
    "          if prompt_messages[-i][\"role\"] == \"assistant\":\n",
    "            prompt_messages[-i][\"role\"] = \"user\"\n",
    "          i += 2\n",
    "      else:\n",
    "        for prompt_message in prompt_messages:\n",
    "          if prompt_message[\"role\"] == \"assistant\":\n",
    "            prompt_message[\"role\"] = assistant_transform_type\n",
    "\n",
    "\n",
    "    # Send to OpenAI API to get a new completion\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "          model=model,\n",
    "          messages = prompt_messages\n",
    "        )\n",
    "    print(f\"Prompt messages sent to OpenAI API:{prompt_messages}\")\n",
    "\n",
    "    # Update database and save it to the right json file\n",
    "\n",
    "    completions.append(completion.model_dump())\n",
    "    name = f\"{model} memory-{memory} {assistant_transform_type}\"\n",
    "    with open(f\"{name}.json\", \"w\") as json_file:\n",
    "        json.dump(completions,json_file)\n",
    "\n",
    "create_completions(name,n,memory,stable_system_message,assistant_transform,assistant_transform_type,first_prompt)\n",
    "\n",
    "\n",
    "## Display data\n",
    "\n",
    "# Load the JSON file\n",
    "\n",
    "file_path = f\"{name}.json\"\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Normalize the JSON data in completions\n",
    "\n",
    "normalized_data = pd.json_normalize(data, record_path='choices', meta=[\n",
    "    'id', 'created', 'model', 'object', 'service_tier', 'system_fingerprint', \n",
    "    ['usage', 'completion_tokens'], ['usage', 'prompt_tokens'], ['usage', 'total_tokens']], sep='.',\n",
    "    meta_prefix='', record_prefix='choices.')\n",
    "\n",
    "# Make more important columns more visible\n",
    "\n",
    "normalized_data = normalized_data[['choices.message.content', 'model', \n",
    "       'usage.completion_tokens', 'usage.prompt_tokens', 'usage.total_tokens', 'id', \n",
    "       'choices.finish_reason', 'choices.index', 'choices.logprobs', \n",
    "       'choices.message.role', 'choices.message.function_call', 'choices.message.tool_calls', \n",
    "       'created', 'object', 'service_tier', 'system_fingerprint'\n",
    "       ]]\n",
    "\n",
    "# Display\n",
    "\n",
    "text = normalized_data[\"choices.message.content\"].iloc[-1]\n",
    "display_markdown(text, raw=True)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
