{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-2024-08-06\"\n",
    "#MODEL = \"gpt-4o-mini\"\n",
    "#MODEL = \"gpt-3.5-turbo\"\n",
    "#prompt = [{\"role\": \"user\", \"content\": \"\"}]\n",
    "loops = 1\n",
    "#temperature = 1.5\n",
    "#file = f\"{MODEL}/single message/2\" #alphabet/5\"\n",
    "file = \"best chat\"\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from IPython.display import display_markdown\n",
    "import copy\n",
    "\n",
    "client = OpenAI()\n",
    "df_path = os.getcwd()\n",
    "chat = False\n",
    "\n",
    "\n",
    "def transform_roles(chat,assistant_transform_type = \"user-assistant\"):\n",
    "    prompt_messages = copy.deepcopy(chat)\n",
    "    if assistant_transform_type == \"user-assistant\":\n",
    "      i = 1\n",
    "      while i <= len(prompt_messages) and prompt_messages[-i][\"role\"] != \"system\":\n",
    "        if i%2 == 1:\n",
    "          prompt_messages[-i][\"role\"] = \"user\"\n",
    "        else:\n",
    "          prompt_messages[-i][\"role\"] = \"assistant\"\n",
    "        i += 1\n",
    "    else:\n",
    "      for prompt_message in prompt_messages:\n",
    "        if prompt_message[\"role\"] == \"assistant\":\n",
    "          prompt_message[\"role\"] = assistant_transform_type\n",
    "    return prompt_messages\n",
    "def load (path):\n",
    "    with open(path, \"r\") as f:\n",
    "        completions = pd.read_json(f, lines=True)\n",
    "    return completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completions = load(\"completions/gpt-3.5-turbo/alphabet/5\")\n",
    "#completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Response, Eval, Data, Instruction]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Load completions from json, if continuing with a file generated in the past\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(df_path,file), \"r\") as f:\n",
    "        completions = pd.read_json(f, lines=True)\n",
    "\n",
    "# If not, create a new completions database\n",
    "\n",
    "except FileNotFoundError:\n",
    "    completions = pd.DataFrame([],columns=['Response', 'Eval', 'Data', 'Instruction'])\n",
    "    print(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant', 'content': ''},\n",
       " {'role': 'user', 'content': 'Hello! How can I assist you today?'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(loops):\n",
    "    completion = client.chat.completions.create(\n",
    "        messages = prompt,\n",
    "        #temperature = temperature,\n",
    "        model = MODEL,\n",
    "        )\n",
    "    response = completion.choices[0].message.content\n",
    "\n",
    "    data = {'Response': response, 'Eval': \"\", 'Data': {}, 'Instruction': prompt}\n",
    "    data = pd.DataFrame([data])\n",
    "    data.at[0, \"Data\"] = {\"Completion\":completion.to_dict()}\n",
    "    completions = pd.concat([completions, data],ignore_index=True)\n",
    "    completions.to_json(os.path.join(df_path, file), lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions.to_json(os.path.join(df_path, file), lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = load(\"completions/gpt-3.5-turbo/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions_old = load(\"completions/gpt-3.5-turbo/alphabet/6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = pd.concat([completions, completions_old],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Eval</th>\n",
       "      <th>Data</th>\n",
       "      <th>Instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Best</td>\n",
       "      <td>{'Completion': {'id': 'chatcmpl-9wVhPaSkySWAXZ...</td>\n",
       "      <td>[{'role': 'user', 'content': ''}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>{'Completion': {'id': 'chatcmpl-9wVhQtT4UIZdQZ...</td>\n",
       "      <td>[{'role': 'user', 'content': ''}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>{'Completion': {'id': 'chatcmpl-9wVhRf25qD34kt...</td>\n",
       "      <td>[{'role': 'user', 'content': ''}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>{'Completion': {'id': 'chatcmpl-9wVhSqokdZxkUS...</td>\n",
       "      <td>[{'role': 'user', 'content': ''}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>{'Completion': {'id': 'chatcmpl-9wVhSePIGJrAxQ...</td>\n",
       "      <td>[{'role': 'user', 'content': ''}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Additionally, attending technology conferences...</td>\n",
       "      <td></td>\n",
       "      <td>{'Completion': {'id': 'chatcmpl-9wmcebKVPpbyX7...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Stay up to date ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Additionally, attending tech conferences and s...</td>\n",
       "      <td></td>\n",
       "      <td>{'Completion': {'id': 'chatcmpl-9wmcguwws3Hw9E...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Stay up to date ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>\\n\\nAdditionally, attending tech events, confe...</td>\n",
       "      <td></td>\n",
       "      <td>{'Completion': {'id': 'chatcmpl-9wmcizkG3AqW8V...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Stay up to date ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>\\n\\nAdditionally, attending industry conferenc...</td>\n",
       "      <td></td>\n",
       "      <td>{'Completion': {'id': 'chatcmpl-9wmckmUh1b7xo4...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Stay up to date ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>\\n\\nAdditionally, attending industry conferenc...</td>\n",
       "      <td></td>\n",
       "      <td>{'Completion': {'id': 'chatcmpl-9wmcmYLco1hx30...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Stay up to date ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Response  Eval  \\\n",
       "0                   Hello! How can I assist you today?  Best   \n",
       "1                   Hello! How can I assist you today?         \n",
       "2                   Hello! How can I assist you today?         \n",
       "3                   Hello! How can I assist you today?         \n",
       "4                   Hello! How can I assist you today?         \n",
       "..                                                 ...   ...   \n",
       "595  Additionally, attending technology conferences...         \n",
       "596  Additionally, attending tech conferences and s...         \n",
       "597  \\n\\nAdditionally, attending tech events, confe...         \n",
       "598  \\n\\nAdditionally, attending industry conferenc...         \n",
       "599  \\n\\nAdditionally, attending industry conferenc...         \n",
       "\n",
       "                                                  Data  \\\n",
       "0    {'Completion': {'id': 'chatcmpl-9wVhPaSkySWAXZ...   \n",
       "1    {'Completion': {'id': 'chatcmpl-9wVhQtT4UIZdQZ...   \n",
       "2    {'Completion': {'id': 'chatcmpl-9wVhRf25qD34kt...   \n",
       "3    {'Completion': {'id': 'chatcmpl-9wVhSqokdZxkUS...   \n",
       "4    {'Completion': {'id': 'chatcmpl-9wVhSePIGJrAxQ...   \n",
       "..                                                 ...   \n",
       "595  {'Completion': {'id': 'chatcmpl-9wmcebKVPpbyX7...   \n",
       "596  {'Completion': {'id': 'chatcmpl-9wmcguwws3Hw9E...   \n",
       "597  {'Completion': {'id': 'chatcmpl-9wmcizkG3AqW8V...   \n",
       "598  {'Completion': {'id': 'chatcmpl-9wmckmUh1b7xo4...   \n",
       "599  {'Completion': {'id': 'chatcmpl-9wmcmYLco1hx30...   \n",
       "\n",
       "                                           Instruction  \n",
       "0                    [{'role': 'user', 'content': ''}]  \n",
       "1                    [{'role': 'user', 'content': ''}]  \n",
       "2                    [{'role': 'user', 'content': ''}]  \n",
       "3                    [{'role': 'user', 'content': ''}]  \n",
       "4                    [{'role': 'user', 'content': ''}]  \n",
       "..                                                 ...  \n",
       "595  [{'role': 'user', 'content': 'Stay up to date ...  \n",
       "596  [{'role': 'user', 'content': 'Stay up to date ...  \n",
       "597  [{'role': 'user', 'content': 'Stay up to date ...  \n",
       "598  [{'role': 'user', 'content': 'Stay up to date ...  \n",
       "599  [{'role': 'user', 'content': 'Stay up to date ...  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = completions.iloc[n][\"Instruction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant', 'content': ''},\n",
       " {'role': 'user', 'content': 'Hello! How can I assist you today?'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response                      Hello! How can I assist you today?\n",
       "Eval                                                      Common\n",
       "Data           {'Completion': {'id': 'chatcmpl-9wVhPaSkySWAXZ...\n",
       "Instruction                    [{'role': 'user', 'content': ''}]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "completions.iloc[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/Users/janvotava/Desktop/openai/completions/gpt-4o-2024-08-06/chat/temperature-02'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommon\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m completions\u001b[38;5;241m.\u001b[39mloc[n,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tag\n\u001b[0;32m----> 3\u001b[0m completions\u001b[38;5;241m.\u001b[39mto_json(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(df_path, file), lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m selected_response \u001b[38;5;241m=\u001b[39m completions[completions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mstartswith(tag))]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chat:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:2702\u001b[0m, in \u001b[0;36mNDFrame.to_json\u001b[0;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[0m\n\u001b[1;32m   2699\u001b[0m config\u001b[38;5;241m.\u001b[39mis_nonnegative_int(indent)\n\u001b[1;32m   2700\u001b[0m indent \u001b[38;5;241m=\u001b[39m indent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 2702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mto_json(\n\u001b[1;32m   2703\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   2704\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2705\u001b[0m     orient\u001b[38;5;241m=\u001b[39morient,\n\u001b[1;32m   2706\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m   2707\u001b[0m     double_precision\u001b[38;5;241m=\u001b[39mdouble_precision,\n\u001b[1;32m   2708\u001b[0m     force_ascii\u001b[38;5;241m=\u001b[39mforce_ascii,\n\u001b[1;32m   2709\u001b[0m     date_unit\u001b[38;5;241m=\u001b[39mdate_unit,\n\u001b[1;32m   2710\u001b[0m     default_handler\u001b[38;5;241m=\u001b[39mdefault_handler,\n\u001b[1;32m   2711\u001b[0m     lines\u001b[38;5;241m=\u001b[39mlines,\n\u001b[1;32m   2712\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   2713\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   2714\u001b[0m     indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m   2715\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   2716\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   2717\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/json/_json.py:217\u001b[0m, in \u001b[0;36mto_json\u001b[0;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m     s \u001b[38;5;241m=\u001b[39m convert_to_line_delimits(s)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path_or_buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    218\u001b[0m         path_or_buf, mode, compression\u001b[38;5;241m=\u001b[39mcompression, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m    219\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    220\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mwrite(s)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/Users/janvotava/Desktop/openai/completions/gpt-4o-2024-08-06/chat/temperature-02'"
     ]
    }
   ],
   "source": [
    "tag = \"Common\"\n",
    "completions.loc[n,\"Eval\"] = tag\n",
    "completions.to_json(os.path.join(df_path, file), lines=True, orient=\"records\")\n",
    "selected_response = completions[completions[\"Eval\"].apply(lambda x: x.startswith(tag))].iloc[0][\"Response\"]\n",
    "if chat:\n",
    "    messages = copy.deepcopy(completions[completions[\"Eval\"].apply(lambda x: x.startswith(tag))].iloc[0][\"Instruction\"])\n",
    "    messages.append({\"role\": \"assistant\", \"content\": selected_response_response})\n",
    "    prompt = transform_roles(messages)\n",
    "else:\n",
    "    prompt = [{\"role\": \"user\", \"content\": selected_response}]\n",
    "print(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
