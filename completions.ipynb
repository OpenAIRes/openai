{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt messages sent to OpenAI API:[{'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}]\n",
      "Hello! How can I assist you today?\n",
      "Prompt messages sent to OpenAI API:[{'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}]\n",
      "Hello! How can I assist you today?\n",
      "Prompt messages sent to OpenAI API:[{'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}]\n",
      "Hello! How can I assist you today?\n",
      "Prompt messages sent to OpenAI API:[{'role': 'user', 'content': ''}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}]\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Set parameters\n",
    "\n",
    "name = \"1\"\n",
    "model = \"gpt-3.5-turbo\"               # important options: \"gpt-4o-mini\", \"gpt-4o\", \"gpt-3.5-turbo\"\n",
    "loops = 4\n",
    "memory_limit = False\n",
    "memory = 1                            # only in case of limited memory\n",
    "stable_system_message = False\n",
    "assistant_transform = False   \n",
    "assistant_transform_type = \"user\"     # only in case of assistant transform, options: \"user\", \"user-assistant\", \"system\"\n",
    "stream = False\n",
    "\n",
    "first_prompt = [\n",
    "  #{\"role\": \"system\", \"content\": \"\"},\n",
    "  {\"role\": \"user\", \"content\": \"\"}\n",
    "]\n",
    "\n",
    "# Choose or create the right folder with json files\n",
    "\n",
    "folder_name = f\"{model}\"\n",
    "if memory_limit:\n",
    "  folder_name += f\" memory-{memory}\"\n",
    "if assistant_transform:\n",
    "  folder_name += f\" {assistant_transform_type}\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "for loop in range(loops):\n",
    "\n",
    "  # Load completions from json, if continuing with a file generated in the past\n",
    "\n",
    "  try:\n",
    "    with open(f\"{folder_name}/{name}.json\", \"r\") as json_file:\n",
    "      completions=json.load(json_file)\n",
    "\n",
    "  # If not, create a new completions database\n",
    "\n",
    "  except FileNotFoundError:\n",
    "    completions = []\n",
    "\n",
    "  # Collect messages generated so far\n",
    "\n",
    "  messages = first_prompt\n",
    "  for completion in completions:\n",
    "      message = completion[\"choices\"][0][\"message\"]\n",
    "      messages.append({\"role\": message[\"role\"], \"content\": message[\"content\"]}   \n",
    "      )\n",
    "\n",
    "  # Pick prompt messages\n",
    "\n",
    "  if (memory >= len(messages)) or not memory_limit:\n",
    "      prompt_messages = messages\n",
    "  else:\n",
    "      #print(f\"Memory smaller than the entire conversation. Forgetting {len(messages)-memory} messages\")\n",
    "      prompt_messages = []\n",
    "      if stable_system_message:\n",
    "        prompt_messages.append(first_prompt[0])\n",
    "        print(prompt_messages)\n",
    "        print(\"stable_system_message\")\n",
    "      prompt_messages = prompt_messages+messages[(len(messages)-memory):]\n",
    "\n",
    "  # Transform assistant role to assistant and user, user, or system roles\n",
    "\n",
    "  if assistant_transform:\n",
    "    if assistant_transform_type == \"user-assistant\":\n",
    "      i = 1\n",
    "      while i <= len(prompt_messages):\n",
    "        if prompt_messages[-i][\"role\"] == \"assistant\":\n",
    "          prompt_messages[-i][\"role\"] = \"user\"\n",
    "        i += 2\n",
    "    else:\n",
    "      for prompt_message in prompt_messages:\n",
    "        if prompt_message[\"role\"] == \"assistant\":\n",
    "          prompt_message[\"role\"] = assistant_transform_type\n",
    "\n",
    "\n",
    "  # Send to OpenAI API to get a new completion\n",
    "\n",
    "  completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages = prompt_messages,\n",
    "        stream = stream,\n",
    "      )\n",
    "  print(f\"Prompt messages sent to OpenAI API:{prompt_messages}\")\n",
    "  if stream:\n",
    "    all_completion_data = []\n",
    "    content_string = \"\"\n",
    "    for chunk in completion:\n",
    "      all_completion_data.append(chunk)\n",
    "      print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
    "      if type(chunk.choices[0].delta.content) == str:\n",
    "        content_string.join(chunk.choices[0].delta.content)\n",
    "    completion = all_completion_data[0]\n",
    "    delta = completion.choices[0].delta\n",
    "    content = delta.content\n",
    "    completion.choices[0] = delta\n",
    "  else:\n",
    "    print(completion.choices[0].message.content)\n",
    "\n",
    "  # Update database and save it to the right json file\n",
    "\n",
    "  completions.append(completion.model_dump())\n",
    "  with open(f\"{folder_name}/{name}.json\", \"w\") as json_file:\n",
    "      json.dump(completions,json_file)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo/1.json\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Display data\n",
    "\n",
    "# Load the JSON file\n",
    "\n",
    "file_path = f\"{folder_name}/{name}.json\"\n",
    "\n",
    "#file_path = f\"gpt-3.5-turbo memory-1 user/2.json\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Normalize the JSON data in completions\n",
    "\n",
    "normalized_data = pd.json_normalize(data, record_path='choices', meta=[\n",
    "    'id', 'created', 'model', 'object', 'service_tier', 'system_fingerprint', \n",
    "    ['usage', 'completion_tokens'], ['usage', 'prompt_tokens'], ['usage', 'total_tokens']], sep='.',\n",
    "    meta_prefix='', record_prefix='choices.')\n",
    "\n",
    "# Make more important columns more visible\n",
    "\n",
    "normalized_data = normalized_data[['choices.message.content', 'model', \n",
    "       'usage.completion_tokens', 'usage.prompt_tokens', 'usage.total_tokens', 'id', \n",
    "       'choices.finish_reason', 'choices.index', 'choices.logprobs', \n",
    "       'choices.message.role', 'choices.message.function_call', 'choices.message.tool_calls', \n",
    "       'created', 'object', 'service_tier', 'system_fingerprint'\n",
    "       ]]\n",
    "\n",
    "# Display\n",
    "\n",
    "content_all = normalized_data[\"choices.message.content\"]\n",
    "last = content_all.iloc[-1]\n",
    "\n",
    "print(file_path)\n",
    "print(len(content_all))\n",
    "\n",
    "for content in content_all:\n",
    "   display_markdown(content, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
